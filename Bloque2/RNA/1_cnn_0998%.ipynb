{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization as BN\n",
    "from keras.layers import GaussianNoise as GN\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler as LRS\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_classes = 10\n",
    "epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "#### LOAD AND TRANSFORM\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFINE A DATA AUGMENTATION GENERATOR\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "  featurewise_center=True,\n",
    "  featurewise_std_normalization=True,\n",
    "  width_shift_range=0.2,\n",
    "  height_shift_range=0.2,\n",
    "  rotation_range=20,\n",
    "  zoom_range=[1.0,1.2],\n",
    "  horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# Now this is necessary due to the feature normalization: #\n",
    "datagen.fit(x_train)\n",
    "\n",
    "testdatagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    ")\n",
    "\n",
    "testdatagen.fit(x_train)\n",
    "###########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEF A BLOCK CONV + BN + GN + CONV + BN + GN + MAXPOOL \n",
    "def CBGN(model,filters,ishape=0):\n",
    "  if (ishape!=0):\n",
    "    model.add(Conv2D(filters, (3, 3), padding='same',\n",
    "                 input_shape=ishape))\n",
    "  else:\n",
    "    model.add(Conv2D(filters, (3, 3), padding='same'))\n",
    "\n",
    "    \n",
    "  model.add(BN())\n",
    "  model.add(GN(0.3))\n",
    "  model.add(Activation('relu'))\n",
    "\n",
    "  model.add(Conv2D(filters, (3, 3), padding='same'))\n",
    "  model.add(BN())\n",
    "  model.add(GN(0.3))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "gaussian_noise_1 (GaussianNo (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "gaussian_noise_2 (GaussianNo (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "gaussian_noise_3 (GaussianNo (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "gaussian_noise_4 (GaussianNo (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "gaussian_noise_5 (GaussianNo (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "gaussian_noise_6 (GaussianNo (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "gaussian_noise_7 (GaussianNo (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "gaussian_noise_8 (GaussianNo (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 2, 2, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "gaussian_noise_9 (GaussianNo (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "gaussian_noise_10 (GaussianN (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 4,987,946\n",
      "Trainable params: 4,983,978\n",
      "Non-trainable params: 3,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## DEF NN TOPOLOGY  \n",
    "model = Sequential()\n",
    "\n",
    "model=CBGN(model,32,x_train.shape[1:])\n",
    "model=CBGN(model,64)\n",
    "model=CBGN(model,128)\n",
    "model=CBGN(model,256)\n",
    "model=CBGN(model,512)\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OPTIM AND COMPILE\n",
    "opt = SGD(lr=0.1, decay=1e-6)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, cooldown=1,\n",
    "                              patience=10, min_lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 1.9946 - acc: 0.2724 - val_loss: 1.7853 - val_acc: 0.3717\n",
      "Epoch 2/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 1.4616 - acc: 0.4649 - val_loss: 1.3554 - val_acc: 0.5253\n",
      "Epoch 3/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 1.2405 - acc: 0.5536 - val_loss: 1.3149 - val_acc: 0.5770\n",
      "Epoch 4/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 1.0940 - acc: 0.6103 - val_loss: 1.4469 - val_acc: 0.5446\n",
      "Epoch 5/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.9825 - acc: 0.6529 - val_loss: 1.1276 - val_acc: 0.6472\n",
      "Epoch 6/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.8982 - acc: 0.6818 - val_loss: 0.9196 - val_acc: 0.6882\n",
      "Epoch 7/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.8385 - acc: 0.7047 - val_loss: 0.9977 - val_acc: 0.6665\n",
      "Epoch 8/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.7901 - acc: 0.7250 - val_loss: 0.9109 - val_acc: 0.7019\n",
      "Epoch 9/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.7528 - acc: 0.7368 - val_loss: 0.7681 - val_acc: 0.7415\n",
      "Epoch 10/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.7199 - acc: 0.7492 - val_loss: 0.6587 - val_acc: 0.7763\n",
      "Epoch 11/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.6918 - acc: 0.7607 - val_loss: 0.6939 - val_acc: 0.7722\n",
      "Epoch 12/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.6690 - acc: 0.7673 - val_loss: 0.7533 - val_acc: 0.7606\n",
      "Epoch 13/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.6446 - acc: 0.7755 - val_loss: 0.6072 - val_acc: 0.8001\n",
      "Epoch 14/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.6263 - acc: 0.7821 - val_loss: 0.7246 - val_acc: 0.7731\n",
      "Epoch 15/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.6069 - acc: 0.7874 - val_loss: 0.7291 - val_acc: 0.7676\n",
      "Epoch 16/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.5874 - acc: 0.7965 - val_loss: 0.6816 - val_acc: 0.7823\n",
      "Epoch 17/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.5758 - acc: 0.7997 - val_loss: 0.5535 - val_acc: 0.8163\n",
      "Epoch 18/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.5587 - acc: 0.8064 - val_loss: 0.7458 - val_acc: 0.7658\n",
      "Epoch 19/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.5432 - acc: 0.8101 - val_loss: 0.6989 - val_acc: 0.7835\n",
      "Epoch 20/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.5316 - acc: 0.8142 - val_loss: 0.5230 - val_acc: 0.8313\n",
      "Epoch 21/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.5256 - acc: 0.8177 - val_loss: 0.4891 - val_acc: 0.8371\n",
      "Epoch 22/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.5123 - acc: 0.8215 - val_loss: 0.4886 - val_acc: 0.8343\n",
      "Epoch 23/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.4983 - acc: 0.8277 - val_loss: 0.6050 - val_acc: 0.8072\n",
      "Epoch 24/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.4913 - acc: 0.8282 - val_loss: 0.5259 - val_acc: 0.8279\n",
      "Epoch 25/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.4784 - acc: 0.8335 - val_loss: 0.5225 - val_acc: 0.8316\n",
      "Epoch 26/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.4701 - acc: 0.8353 - val_loss: 0.6201 - val_acc: 0.8079\n",
      "Epoch 27/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.4656 - acc: 0.8368 - val_loss: 0.4394 - val_acc: 0.8554\n",
      "Epoch 28/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.4572 - acc: 0.8407 - val_loss: 0.5010 - val_acc: 0.8437\n",
      "Epoch 29/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.4531 - acc: 0.8419 - val_loss: 0.4706 - val_acc: 0.8405\n",
      "Epoch 30/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.4436 - acc: 0.8456 - val_loss: 0.5458 - val_acc: 0.8234\n",
      "Epoch 31/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.4377 - acc: 0.8475 - val_loss: 0.4915 - val_acc: 0.8395\n",
      "Epoch 32/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.4262 - acc: 0.8522 - val_loss: 0.4803 - val_acc: 0.8474\n",
      "Epoch 33/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.4212 - acc: 0.8546 - val_loss: 0.4510 - val_acc: 0.8512\n",
      "Epoch 34/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.4149 - acc: 0.8545 - val_loss: 0.4602 - val_acc: 0.8489\n",
      "Epoch 35/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.4052 - acc: 0.8574 - val_loss: 0.5193 - val_acc: 0.8355\n",
      "Epoch 36/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.4056 - acc: 0.8598 - val_loss: 0.5012 - val_acc: 0.8398\n",
      "Epoch 37/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.3971 - acc: 0.8625 - val_loss: 0.4151 - val_acc: 0.8626\n",
      "Epoch 38/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.3930 - acc: 0.8633 - val_loss: 0.5441 - val_acc: 0.8321\n",
      "Epoch 39/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.3847 - acc: 0.8650 - val_loss: 0.4046 - val_acc: 0.8687\n",
      "Epoch 40/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.3802 - acc: 0.8671 - val_loss: 0.4052 - val_acc: 0.8666\n",
      "Epoch 41/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.3753 - acc: 0.8677 - val_loss: 0.4484 - val_acc: 0.8581\n",
      "Epoch 42/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.3714 - acc: 0.8695 - val_loss: 0.3868 - val_acc: 0.8744\n",
      "Epoch 43/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.3612 - acc: 0.8734 - val_loss: 0.4722 - val_acc: 0.8476\n",
      "Epoch 44/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.3602 - acc: 0.8752 - val_loss: 0.4091 - val_acc: 0.8702\n",
      "Epoch 45/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.3551 - acc: 0.8761 - val_loss: 0.4365 - val_acc: 0.8610\n",
      "Epoch 46/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.3504 - acc: 0.8757 - val_loss: 0.4240 - val_acc: 0.8673\n",
      "Epoch 47/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.3495 - acc: 0.8767 - val_loss: 0.4306 - val_acc: 0.8631\n",
      "Epoch 48/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.3475 - acc: 0.8786 - val_loss: 0.4250 - val_acc: 0.8618\n",
      "Epoch 49/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.3455 - acc: 0.8782 - val_loss: 0.4125 - val_acc: 0.8641\n",
      "Epoch 50/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.3320 - acc: 0.8819 - val_loss: 0.4186 - val_acc: 0.8672\n",
      "Epoch 51/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.3331 - acc: 0.8835 - val_loss: 0.4933 - val_acc: 0.8431\n",
      "Epoch 52/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.3269 - acc: 0.8848 - val_loss: 0.4105 - val_acc: 0.8715\n",
      "Epoch 53/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2919 - acc: 0.8978 - val_loss: 0.3544 - val_acc: 0.8856\n",
      "Epoch 54/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2842 - acc: 0.8999 - val_loss: 0.3784 - val_acc: 0.8857\n",
      "Epoch 55/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2797 - acc: 0.9014 - val_loss: 0.3642 - val_acc: 0.8846\n",
      "Epoch 56/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2831 - acc: 0.8992 - val_loss: 0.3815 - val_acc: 0.8779\n",
      "Epoch 57/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2764 - acc: 0.9036 - val_loss: 0.3574 - val_acc: 0.8850\n",
      "Epoch 59/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2723 - acc: 0.9042 - val_loss: 0.3342 - val_acc: 0.8944\n",
      "Epoch 60/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2695 - acc: 0.9047 - val_loss: 0.3358 - val_acc: 0.8905\n",
      "Epoch 61/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2693 - acc: 0.9046 - val_loss: 0.3557 - val_acc: 0.8890\n",
      "Epoch 62/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2649 - acc: 0.9065 - val_loss: 0.3781 - val_acc: 0.8835\n",
      "Epoch 63/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2636 - acc: 0.9072 - val_loss: 0.3841 - val_acc: 0.8825\n",
      "Epoch 64/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2644 - acc: 0.9064 - val_loss: 0.3323 - val_acc: 0.8918\n",
      "Epoch 65/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2543 - acc: 0.9090 - val_loss: 0.3537 - val_acc: 0.8889\n",
      "Epoch 66/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2572 - acc: 0.9074 - val_loss: 0.3735 - val_acc: 0.8830\n",
      "Epoch 67/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2552 - acc: 0.9093 - val_loss: 0.3364 - val_acc: 0.8939\n",
      "Epoch 68/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2486 - acc: 0.9116 - val_loss: 0.3605 - val_acc: 0.8870\n",
      "Epoch 69/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2502 - acc: 0.9113 - val_loss: 0.3352 - val_acc: 0.8954\n",
      "Epoch 70/150\n",
      "243/500 [=============>................] - ETA: 6s - loss: 0.2352 - acc: 0.9146"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2432 - acc: 0.9134 - val_loss: 0.3443 - val_acc: 0.8928\n",
      "Epoch 73/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2440 - acc: 0.9131 - val_loss: 0.3566 - val_acc: 0.8923\n",
      "Epoch 74/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2389 - acc: 0.9146 - val_loss: 0.3778 - val_acc: 0.8855\n",
      "Epoch 75/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2243 - acc: 0.9191 - val_loss: 0.3248 - val_acc: 0.9006\n",
      "Epoch 76/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2180 - acc: 0.9221 - val_loss: 0.3303 - val_acc: 0.8980\n",
      "Epoch 77/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2139 - acc: 0.9237 - val_loss: 0.3381 - val_acc: 0.8972\n",
      "Epoch 79/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2118 - acc: 0.9248 - val_loss: 0.3362 - val_acc: 0.8988\n",
      "Epoch 80/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2197 - acc: 0.9211 - val_loss: 0.3566 - val_acc: 0.8924\n",
      "Epoch 81/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2074 - acc: 0.9259 - val_loss: 0.3437 - val_acc: 0.8954\n",
      "Epoch 82/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2150 - acc: 0.9232 - val_loss: 0.3505 - val_acc: 0.8935\n",
      "Epoch 83/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2097 - acc: 0.9262 - val_loss: 0.3402 - val_acc: 0.8980\n",
      "Epoch 84/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2112 - acc: 0.9261 - val_loss: 0.3279 - val_acc: 0.8989\n",
      "Epoch 85/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.2094 - acc: 0.9246 - val_loss: 0.3266 - val_acc: 0.8995\n",
      "Epoch 86/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1977 - acc: 0.9289 - val_loss: 0.3282 - val_acc: 0.9005\n",
      "Epoch 87/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1964 - acc: 0.9304 - val_loss: 0.3196 - val_acc: 0.9024\n",
      "Epoch 88/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1970 - acc: 0.9297 - val_loss: 0.3278 - val_acc: 0.9025\n",
      "Epoch 89/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1989 - acc: 0.9293 - val_loss: 0.3252 - val_acc: 0.9028\n",
      "Epoch 90/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1925 - acc: 0.9315 - val_loss: 0.3263 - val_acc: 0.9033\n",
      "Epoch 91/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1930 - acc: 0.9303 - val_loss: 0.3318 - val_acc: 0.9013\n",
      "Epoch 92/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1935 - acc: 0.9307 - val_loss: 0.3297 - val_acc: 0.9017\n",
      "Epoch 93/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1927 - acc: 0.9319 - val_loss: 0.3335 - val_acc: 0.8997\n",
      "Epoch 94/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1924 - acc: 0.9309 - val_loss: 0.3214 - val_acc: 0.9054\n",
      "Epoch 95/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1916 - acc: 0.9313 - val_loss: 0.3389 - val_acc: 0.8990\n",
      "Epoch 96/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1874 - acc: 0.9330 - val_loss: 0.3241 - val_acc: 0.9032\n",
      "Epoch 97/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1884 - acc: 0.9329 - val_loss: 0.3403 - val_acc: 0.8991\n",
      "Epoch 98/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1868 - acc: 0.9320 - val_loss: 0.3256 - val_acc: 0.9029\n",
      "Epoch 99/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1849 - acc: 0.9336 - val_loss: 0.3223 - val_acc: 0.9048\n",
      "Epoch 100/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1850 - acc: 0.9346 - val_loss: 0.3222 - val_acc: 0.9030\n",
      "Epoch 101/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1838 - acc: 0.9345 - val_loss: 0.3309 - val_acc: 0.9023\n",
      "Epoch 102/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1864 - acc: 0.9343 - val_loss: 0.3260 - val_acc: 0.9030\n",
      "Epoch 103/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1832 - acc: 0.9354 - val_loss: 0.3200 - val_acc: 0.9032\n",
      "Epoch 104/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1798 - acc: 0.9349 - val_loss: 0.3234 - val_acc: 0.9027\n",
      "Epoch 105/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1799 - acc: 0.9345 - val_loss: 0.3388 - val_acc: 0.8998\n",
      "Epoch 106/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1794 - acc: 0.9344 - val_loss: 0.3235 - val_acc: 0.9043\n",
      "Epoch 107/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1843 - acc: 0.9342 - val_loss: 0.3216 - val_acc: 0.9050\n",
      "Epoch 108/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1814 - acc: 0.9344 - val_loss: 0.3268 - val_acc: 0.9035\n",
      "Epoch 109/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1823 - acc: 0.9344 - val_loss: 0.3256 - val_acc: 0.9039\n",
      "Epoch 110/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1803 - acc: 0.9349 - val_loss: 0.3245 - val_acc: 0.9048\n",
      "Epoch 111/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1822 - acc: 0.9355 - val_loss: 0.3283 - val_acc: 0.9042\n",
      "Epoch 112/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1798 - acc: 0.9360 - val_loss: 0.3284 - val_acc: 0.9043\n",
      "Epoch 113/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1776 - acc: 0.9353 - val_loss: 0.3204 - val_acc: 0.9056\n",
      "Epoch 114/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1765 - acc: 0.9379 - val_loss: 0.3208 - val_acc: 0.9062\n",
      "Epoch 115/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1788 - acc: 0.9354 - val_loss: 0.3227 - val_acc: 0.9046\n",
      "Epoch 116/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1760 - acc: 0.9373 - val_loss: 0.3223 - val_acc: 0.9066\n",
      "Epoch 117/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1803 - acc: 0.9352 - val_loss: 0.3264 - val_acc: 0.9037\n",
      "Epoch 118/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1750 - acc: 0.9386 - val_loss: 0.3247 - val_acc: 0.9049\n",
      "Epoch 119/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1745 - acc: 0.9381 - val_loss: 0.3308 - val_acc: 0.9035\n",
      "Epoch 120/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1743 - acc: 0.9369 - val_loss: 0.3249 - val_acc: 0.9039\n",
      "Epoch 121/150\n",
      "481/500 [===========================>..] - ETA: 0s - loss: 0.1769 - acc: 0.9355"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1714 - acc: 0.9375 - val_loss: 0.3288 - val_acc: 0.9040\n",
      "Epoch 136/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1710 - acc: 0.9390 - val_loss: 0.3282 - val_acc: 0.9042\n",
      "Epoch 137/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1753 - acc: 0.9371 - val_loss: 0.3300 - val_acc: 0.9037\n",
      "Epoch 138/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1732 - acc: 0.9384 - val_loss: 0.3282 - val_acc: 0.9035\n",
      "Epoch 139/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1693 - acc: 0.9397 - val_loss: 0.3311 - val_acc: 0.9053\n",
      "Epoch 140/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1732 - acc: 0.9380 - val_loss: 0.3228 - val_acc: 0.9055\n",
      "Epoch 141/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1738 - acc: 0.9374 - val_loss: 0.3283 - val_acc: 0.9045\n",
      "Epoch 142/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1688 - acc: 0.9400 - val_loss: 0.3284 - val_acc: 0.9046\n",
      "Epoch 143/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1744 - acc: 0.9371 - val_loss: 0.3314 - val_acc: 0.9035\n",
      "Epoch 144/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1710 - acc: 0.9381 - val_loss: 0.3315 - val_acc: 0.9022\n",
      "Epoch 145/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1695 - acc: 0.9391 - val_loss: 0.3278 - val_acc: 0.9044\n",
      "Epoch 146/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1714 - acc: 0.9381 - val_loss: 0.3288 - val_acc: 0.9034\n",
      "Epoch 147/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1707 - acc: 0.9386 - val_loss: 0.3277 - val_acc: 0.9039\n",
      "Epoch 148/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1707 - acc: 0.9384 - val_loss: 0.3322 - val_acc: 0.9042\n",
      "Epoch 149/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1685 - acc: 0.9407 - val_loss: 0.3296 - val_acc: 0.9041\n",
      "Epoch 150/150\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.1651 - acc: 0.9411 - val_loss: 0.3288 - val_acc: 0.9044\n"
     ]
    }
   ],
   "source": [
    "## TRAINING with DA and LRA\n",
    "history=model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),\n",
    "                            steps_per_epoch=len(x_train) / batch_size, \n",
    "                            epochs=epochs,\n",
    "                            validation_data=testdatagen.flow(x_test, y_test),\n",
    "                            callbacks=[reduce_lr],\n",
    "                            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 5ms/step\n",
      "Test loss: 0.32875621743500233\n",
      "Test accuracy: 0.904400001168251\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate_generator(testdatagen.flow(x_test, y_test,batch_size=batch_size), verbose=1)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save('cnn9044.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  \"Accuracy\"\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.savefig('gila.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prova1",
   "language": "python",
   "name": "prova1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
